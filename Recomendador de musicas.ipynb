{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V53DcJTTOKoJ"
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSFuWCaorKNl"
   },
   "source": [
    "## Dicionário dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k8yJHAYt6re"
   },
   "source": [
    "[Spotify API](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUy5Ex8VrPe-"
   },
   "source": [
    "* `Acousticness/Acústica:` Variável numérica, medida de confiança de 0,0 a 1,0 se a faixa é acústica. 1.0 representa alta confiança de que a faixa é acústica.\n",
    "\n",
    "* `Danceability/Dançabilidade:` Variável numérica, a dançabilidade descreve o quão adequada uma faixa é para dançar com base em uma combinação de elementos musicais, incluindo tempo, estabilidade do ritmo, força da batida e regularidade geral. Um valor de 0,0 é o menos dançável e 1,0 é o mais dançável.\n",
    "\n",
    "* `Duration_ms:`Variável numérica, a duração da trilha em milissegundos.\n",
    "\n",
    "* `Duration_min:` Variável numérica, a duração da faixa em minutos.\n",
    "\n",
    "* `Energy/Energia:` Variável numérica, Energia é uma medida de 0,0 a 1,0 e representa uma medida perceptiva de intensidade e atividade. Normalmente, as faixas energéticas parecem rápidas, altas e barulhentas. Por exemplo, o death metal tem alta energia, enquanto um prelúdio de Bach tem uma pontuação baixa na escala. As características perceptivas que contribuem para este atributo incluem faixa dinâmica, intensidade percebida, timbre, taxa de início e entropia geral.\n",
    "\n",
    "* `Explicit/Explícito:` Variável categórica, se a faixa tem ou não letras explícitas (verdadeiro = sim (1); falso = não(0), não OU desconhecido).\n",
    "\n",
    "* `Id:` O ID do Spotify para a faixa.\n",
    "\n",
    "* `Instrumentalness/Instrumentalidade:` Variável numérica, prevê se uma faixa não contém vocais. Os sons “Ooh” e “aah” são tratados como instrumentais neste contexto. Faixas de rap ou de palavras faladas são claramente “vocais”. Quanto mais próximo o valor de instrumentalidade estiver de 1,0, maior a probabilidade de a faixa não conter conteúdo vocal. Valores acima de 0,5 destinam-se a representar faixas instrumentais, mas a confiança é maior à medida que o valor se aproxima de 1,0.\n",
    "\n",
    "* `Key/Chave:`Variável numérica, a chave geral estimada da faixa. Os inteiros são mapeados para pitchs usando a notação padrão de Pitch Class. Por exemplo. 0 = C, 1 = C#/Db, 2 = D, e assim por diante. Se nenhuma chave foi detectada, o valor é -1.\n",
    "\n",
    "* `Liveness/ Ao vivo:` Variável numérica, detecta a presença de um público na gravação. Valores mais altos de vivacidade representam uma probabilidade maior de que a faixa tenha sido executada ao vivo. Um valor acima de 0,8 fornece uma forte probabilidade de que a faixa esteja ativa.\n",
    "\n",
    "* `Loudness/ Volume em dB:` Variável numérica, volume geral de uma faixa em decibéis (dB). Os valores de volume são calculados em média em toda a faixa e são úteis para comparar o volume relativo das faixas. A sonoridade é a qualidade de um som que é o principal correlato psicológico da força física (amplitude). Os valores típicos variam entre -60 e 0 db.\n",
    "\n",
    "* `Mode/ Modo:` Variável numérica, o modo indica a modalidade (maior ou menor) de uma faixa, o tipo de escala da qual seu conteúdo melódico é derivado. Maior é representado por 1 e menor é 0.\n",
    "\n",
    "* `Popularity/Popularidade:` Variável numérica, a popularidade de uma faixa é um valor entre 0 e 100, sendo 100 o mais popular. A popularidade é calculada por algoritmo e é baseada, em grande parte, no número total de execuções que a faixa teve e quão recentes são essas execuções.\n",
    "\n",
    "* `Speechiness/Fala:` Variável numérica, a fala detecta a presença de palavras faladas em uma faixa. Quanto mais exclusivamente falada a gravação (por exemplo, talk show, audiolivro, poesia), mais próximo de 1,0 o valor do atributo. Valores acima de 0,66 descrevem faixas que provavelmente são feitas inteiramente de palavras faladas. Valores entre 0,33 e 0,66 descrevem faixas que podem conter música e fala, seja em seções ou em camadas, incluindo casos como música rap. Os valores abaixo de 0,33 provavelmente representam músicas e outras faixas que não são de fala.\n",
    "\n",
    "* `Tempo:` Variável numérica, Tempo estimado geral de uma faixa em batidas por minuto (BPM). Na terminologia musical, tempo é a velocidade ou ritmo de uma determinada peça e deriva diretamente da duração média da batida.\n",
    "\n",
    "* `Valence/Valência:` Variável numérica, Medida de 0,0 a 1,0 descrevendo a positividade musical transmitida por uma faixa. Faixas com alta valência soam mais positivas (por exemplo, feliz, alegre, eufórica), enquanto faixas com baixa valência soam mais negativas (por exemplo, triste, deprimida, irritada).\n",
    "\n",
    "* `Year/Ano:` Ano em que a música foi lançada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAHYpvk-qyjz"
   },
   "source": [
    "## Analise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdWWbAopV3tT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('Dados_totais.csv')\n",
    "dados_generos = pd.read_csv('data_by_genres.csv')\n",
    "dados_anos = pd.read_csv('data_by_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dados.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(['explicit', 'key', 'mode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos.drop(['mode', 'key'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos.drop(['mode', 'key'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos = dados_anos[dados_anos['year']>=2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_anos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf0u9LxLwkRq"
   },
   "source": [
    "## Análise gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzAoFn6SV4Zj"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(dados_anos, x=\"year\", y=\"loudness\", markers= True, title='Variação do loudness conforme os anos')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['acousticness'], name='Acousticness'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['valence'], name='Valence'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['danceability'], name='Danceability'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['energy'], name='Energy'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['instrumentalness'], name='Instrumentalness'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['liveness'], name='Liveness'))\n",
    "fig.add_trace(go.Scatter(x=dados_anos['year'], y=dados_anos['speechiness'], name='Speechiness'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(dados.corr(), text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8Cj61yTOH44"
   },
   "source": [
    "# Clusterização por gênero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBnt__8-x0Kc"
   },
   "source": [
    "## PCA e SdandartScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWPqMzeHV2Pz"
   },
   "outputs": [],
   "source": [
    "dados_generos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos['genres'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos1 = dados_generos.drop(['genres'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_generos1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk832DN7z1qk"
   },
   "source": [
    "Agora vamos utilizar vários conceitos em um processo de pipeline, então a primeira coisa que vamos fazer é importar o método **Pipeline** do [sklearn.pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) e esse método faz literalmente uma pipeline de machine learning, mas de uma forma automática, onde aplica sequencialmente uma lista de transformações até um resultado final. Então o que precisamos passar é o que a nossa pipeline vai fazer, como o primeiro passo e o que queremos de resultado final dela. \n",
    "\n",
    "Neste ponto precisamos reduzir a dimensionalidade da tabela que está com várias colunas, porém se utilizarmos um processo de redução diretamente, sem fazer a padronização dos dados na parte de pré processamento, os resultados ficarão totalmente desbalanceados, trazendo maior peso para as variáveis que têm uma amplitude maior, como por exemplo o loudness em relação às outras variáveis que compõem a música.\n",
    "\n",
    "Para resolver esse problema, o primeiro passo da pipeline vai ser usar o [**StandardScaler**](https://scikit-learn.org/stable/modules/preprocessing.html) para trazer essa normalização e redução de escala para que no próximo passo seja feita a redução de dimensionalidade com um método de decomposição, no nosso caso vamos escolher o PCA.\n",
    "\n",
    "PCA significa Análise de componentes principais e ele trás consigo uma série de análises matemáticas que são feitas para que possamos transformar aquelas milhares de colunas que temos em uma quantidade menor, com um valor n que escolhermos, porém, quanto mais colunas a gente tem no dataset original e menos colunas queremos no dataset final, o aprendizado depois pode ser prejudicado.\n",
    "\n",
    "Na parte **n_components** podemos colocar a quantidade de % de explicação que queremos que o algoritmo tenha no final, como por exemplo 0.3, que seria 30%, ou um valor como por exemplo um valor X de colunas.\n",
    "\n",
    "Depois de feita a pipeline, vamos salvar em um arquivo chamado projection, com as colunas x e y, que são as posições dos pontos na cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6Wmr4XGV-07"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBhEdOWWV_FL"
   },
   "outputs": [],
   "source": [
    "SEED = 1224\n",
    "np.random.seed(1224)\n",
    "\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2, random_state=SEED))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_pca = pca_pipeline.fit_transform(dados_generos1)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcYvAz91-jAn"
   },
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYjIkWmJV_r7"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz8IPKohAPVJ"
   },
   "source": [
    "Depois de fazer a normalização e redução de dimensionalidade,conseguimos gerar os pontos de x e y que temos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCbVYCo6V_9b"
   },
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters=5, n_init=10, random_state=SEED)\n",
    "\n",
    "kmeans_pca.fit(projection)\n",
    "\n",
    "dados_generos['cluster_pca'] = kmeans_pca.predict(projection)\n",
    "projection['cluster_pca'] = kmeans_pca.predict(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection['generos'] = dados_generos['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3617DeF_4FR"
   },
   "source": [
    "## Plotando os clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG9-sg2GWAX8"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "   projection, x='x', y='y', color='cluster_pca', hover_data=['x', 'y', 'generos'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline[1].explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline[1].explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl2upg8t__25"
   },
   "source": [
    "# Clusterização por música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFlEqVHd_9qq"
   },
   "source": [
    "## Redução de dimensionalidade com PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoh4XYpoWB4L"
   },
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['artists'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['artists_song'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(dtype=int)\n",
    "colunas_ohe = ohe.fit_transform(dados[['artists']]).toarray()\n",
    "dados2 = dados.drop('artists', axis=1)\n",
    "\n",
    "dados_musicas_dummies = pd.concat([dados2, pd.DataFrame(colunas_ohe, columns=ohe.get_feature_names_out(['artists']))], axis=1)\n",
    "dados_musicas_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_musicas_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=0.7, random_state=SEED))])\n",
    "\n",
    "\n",
    "music_embedding_pca = pca_pipeline.fit_transform(dados_musicas_dummies.drop(['id','name','artists_song'], axis=1))\n",
    "projection_m = pd.DataFrame(data=music_embedding_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline[1].n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY-2xm5y3u93"
   },
   "source": [
    "## Aplicação do cluster com K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SI3Yg8o1WCM7"
   },
   "outputs": [],
   "source": [
    "kmeans_pca_pipeline = KMeans(n_clusters=50, n_init=10, random_state=SEED)\n",
    "\n",
    "kmeans_pca_pipeline.fit(projection_m)\n",
    "\n",
    "dados['cluster_pca'] = kmeans_pca_pipeline.predict(projection_m)\n",
    "projection_m['cluster_pca'] = kmeans_pca_pipeline.predict(projection_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_m['artist'] = dados['artists']\n",
    "projection_m['song'] = dados['artists_song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjl9truJ4CCj"
   },
   "source": [
    "## Analisando o cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXXQHGtIWCs7"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "   projection_m, x=0, y=1, color='cluster_pca', hover_data=[0, 1, 'song'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "   projection_m, x=0, y=1, z=2, color='cluster_pca',hover_data=['song'])\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline[1].explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline[1].explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_jPt0TF3WRT"
   },
   "source": [
    "# Sistemas de Recomendação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qai3pGtWUFl-"
   },
   "source": [
    "## Recomendação da música"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqAO2gE5WDmb"
   },
   "outputs": [],
   "source": [
    "nome_musica = '50 Cent - P.I.M.P.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.dtypes.cast import maybe_upcast\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = list(projection_m[projection_m['song']== nome_musica]['cluster_pca'])[0]\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicas_recomendadas = projection_m[projection_m['cluster_pca']== cluster][[0, 1, 'song']]\n",
    "musicas_recomendadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_musica = list(projection_m[projection_m['song']== nome_musica][0])[0]\n",
    "x_musica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_musica = list(projection_m[projection_m['song']== nome_musica][1])[0]\n",
    "y_musica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distâncias euclidianas\n",
    "distancias = euclidean_distances(musicas_recomendadas[[0, 1]], [[x_musica, y_musica]])\n",
    "musicas_recomendadas['id'] = dados['id']\n",
    "musicas_recomendadas['distancias']= distancias\n",
    "recomendada = musicas_recomendadas.sort_values('distancias').head(10)\n",
    "recomendada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euvxau8aVlwP"
   },
   "source": [
    "## Biblioteca Spotipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.spotify.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iwte0IQWEGD"
   },
   "outputs": [],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzJAzu_7V-Lm"
   },
   "source": [
    "**ATENÇÃO!**\n",
    "\n",
    "Antes de rodar essa parte do código, você precisa fazer uma conta na API do Spotify e gerar suas próprias **client_id** e **client_secret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFDspvpNWEgL"
   },
   "outputs": [],
   "source": [
    "scope = \"user-library-read playlist-modify-private\"\n",
    "OAuth = SpotifyOAuth(\n",
    "        scope=scope,         \n",
    "        redirect_uri='http://localhost:5000/callback',\n",
    "        client_id = '4b73846f7146404c8692e790036fb473',\n",
    "        client_secret = '88b6bec62f84467f9c9b250aa42e296e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id = '4b73846f7146404c8692e790036fb473',\n",
    "                                                      client_secret = '88b6bec62f84467f9c9b250aa42e296e')\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhGpa5Rw1YwL"
   },
   "source": [
    "## Imagem do álbum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Sg5j0FyWE57"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#achando o ID\n",
    "nome_musica = '50 Cent - P.I.M.P.'\n",
    "music_id = dados[dados['artists_song']== nome_musica]['id'].iloc[0]\n",
    "music_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na API\n",
    "track = sp.track(music_id)\n",
    "url = track[\"album\"][\"images\"][1][\"url\"]\n",
    "name = track[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mexendo com a imagem\n",
    "image = io.imread(url)\n",
    "plt.imshow(image)\n",
    "plt.xlabel(name, fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kLStrMVUERu"
   },
   "source": [
    "# Recomendador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eG7AfLX0lW6"
   },
   "source": [
    "## Buscando os dados da playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYjznr4wWFpa"
   },
   "outputs": [],
   "source": [
    "def recommend_id(playlist_id):\n",
    "    url = []\n",
    "    name = []\n",
    "    artists = []\n",
    "    duracao = []\n",
    "    for i in playlist_id:\n",
    "        track = sp.track(i)\n",
    "        url.append(track[\"album\"][\"images\"][1][\"url\"])\n",
    "        name.append(track[\"name\"])\n",
    "        artists.append(track[\"artists\"][0][\"name\"])\n",
    "        duracao.append(round(track[\"duration_ms\"]/60000, 2))\n",
    "    return name, url, artists, duracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, url, artists, duracao = recommend_id(recomendada['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, url, artists, duracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbJbLZdQSSOL"
   },
   "source": [
    "## Gerando as imagens da playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnpfnEZCWGED"
   },
   "outputs": [],
   "source": [
    "def visualize_songs(name, url):\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    columns = 5\n",
    "\n",
    "    for i, u in enumerate(url): \n",
    "        # define o ax como o subplot, com a divisão que retorna inteiro do número urls pelas colunas + 1 (no caso, 6)\n",
    "        ax = plt.subplot(len(url) // columns + 1, columns, i + 1)\n",
    "\n",
    "        # Lendo a imagem com o Scikit Image\n",
    "        image = io.imread(u)\n",
    "\n",
    "        # Mostra a imagem\n",
    "        plt.imshow(image)\n",
    "\n",
    "        # Para deixar o eixo Y invisível \n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # xticks define o local que vamos trocar os rótulos do eixo x, nesse caso, deixar os pontos de marcação brancos\n",
    "        plt.xticks(color = 'w', fontsize = 0.1)\n",
    "\n",
    "        # yticks define o local que vamos trocar os rótulos do eixo y, nesse caso, deixar os pontos de marcação brancos\n",
    "        plt.yticks(color = 'w', fontsize = 0.1)\n",
    "\n",
    "        # Colocando o nome da música no eixo x\n",
    "        plt.xlabel(name[i], fontsize = 8)\n",
    "\n",
    "        # Faz com que todos os parâmetros se encaixem no tamanho da imagem definido\n",
    "        plt.tight_layout(h_pad=0.7, w_pad=0)\n",
    "\n",
    "        # Ajusta os parâmetros de layout da imagem.\n",
    "        # wspace = A largura do preenchimento entre subparcelas, como uma fração da largura média dos eixos.\n",
    "        # hspace = A altura do preenchimento entre subparcelas, como uma fração da altura média dos eixos.\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "\n",
    "        # Remove os ticks - marcadores, do eixo x, sem remover o eixo todo, deixando o nome da música.\n",
    "        plt.tick_params(bottom = False)\n",
    "\n",
    "        # Tirar a grade da imagem, gerada automaticamente pelo matplotlib\n",
    "        plt.grid(visible=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_songs(name, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH78D_CpVo3l"
   },
   "source": [
    "## Fazendo uma função final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HndokkNsWGj8"
   },
   "outputs": [],
   "source": [
    "def recomendador(nome_musica):\n",
    "\n",
    "    ## Calculando as distâncias\n",
    "    cluster = list(projection_m[projection_m['song']== nome_musica]['cluster_pca'])[0]\n",
    "    musicas_recomendadas = projection_m[projection_m['cluster_pca']== cluster][[0, 1, 'song']]\n",
    "    x_musica = list(projection_m[projection_m['song']== nome_musica][0])[0]\n",
    "    y_musica = list(projection_m[projection_m['song']== nome_musica][1])[0]\n",
    "    distancias = euclidean_distances(musicas_recomendadas[[0, 1]], [[x_musica, y_musica]])\n",
    "    musicas_recomendadas['id'] = dados['id']\n",
    "    musicas_recomendadas['distancias'] = distancias\n",
    "    recomendada = musicas_recomendadas.sort_values('distancias').head(10)\n",
    "\n",
    "    # ## Acessando os dados de cada música com a biblioteca Spotipy (nome e imagem)\n",
    "    playlist_id = recomendada['id']\n",
    "\n",
    "    url = []\n",
    "    name = []\n",
    "    for i in playlist_id:\n",
    "        track = sp.track(i)\n",
    "        url.append(track[\"album\"][\"images\"][1][\"url\"])\n",
    "        name.append(track[\"name\"])\n",
    "\n",
    "    # ## Plotando as figuras\n",
    "    plt.figure(figsize=(15,10))\n",
    "    columns = 5\n",
    "    for i, u in enumerate(url):\n",
    "        ax = plt.subplot(len(url) // columns + 1, columns, i + 1)\n",
    "        images = io.imread(u)\n",
    "        plt.imshow(images)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.xticks(color = 'w', fontsize = 0.1)\n",
    "        plt.yticks(color = 'w', fontsize = 0.1)\n",
    "        plt.xlabel(name[i], fontsize = 10)\n",
    "        plt.tight_layout(h_pad=0.7, w_pad=0)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "        plt.grid(visible=None)\n",
    "        plt.tick_params(bottom = False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendador('50 Cent - P.I.M.P.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Recomendador de musicas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
